#!/bin/bash

cd /fastapi_RAG_container

IP=${IP:-0.0.0.0}
PORT=${PORT:-8090}
WORKERS=${WORKERS:-1}

RAG_MODELNAME=${RAG_MODELNAME:-"FAU LLM 2.0"}
PLAIN_MODELNAME=${PLAIN_MODELNAME}
OPENAI_API_URL=${OPENAI_URL:-"http://api.openai.com/v1/chat/completions"}
OPENAI_API_KEY=${OPENAI_API_KEY:-"FIXME: No API key specified"}
OPENAI_LLM_MODEL=${OPENAI_LLM_MODEL:-"gpt-4o-mini"}

if [ ! "x$PLAIN_MODELNAME" = "x" ]; then
PLAIN=",
    \"${PLAIN_MODELNAME}\": {
      \"base_url\": \"${OPENAIL_API_URL}\",
      \"api_key\": \"{$OPENAI_API_KEY}\",
      \"model\": \"${OPENAI_LLM_MODEL}\"
    }
"
fi

cat << EOF > config.json
{
  "_comment": "Autogenerated by /entrypoint.sh",
  "llm": {
    "$RAG_MODELNAME": {
      "base_url": "${OPENAI_API_URL}",
      "api_key": "${OPENAI_API_KEY}",
      "model": "${OPENAI_LLM_MODEL}"
    }
  }${PLAIN}
}
EOF

if [ "x$DEBUG" = "xtrue" ]; then
       cat config.json
fi

# Command to run the application
python -m uvicorn fastapi_RAG_service.app.main:app --host ${IP} --port ${PORT} --workers ${WORKERS}
